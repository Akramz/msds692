{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting text from PDFs\n",
    "\n",
    "PDF files are effectively restricted versions of PostScript files, what you might've heard of. PDF files are actually programs in a very simple programming language and hence can display just about anything. Much of what you see inside a PDF file is text, however, and we can grab that text without the layout information using [pdf2txt.py](https://euske.github.io/pdfminer/). Install it with:\n",
    " \n",
    "```bash\n",
    "$ pip install pdfminer\n",
    "```\n",
    "\n",
    "Then use `pdf2txt.py` as a command from the commandline, which will spit the text out to standard output. First download a sample PDF, such as [Dr_Maxwell_Glen_Berry.pdf](https://www.eisenhower.archives.gov/education/articles/Dr_Maxwell_Glen_Berry.pdf), which we can easily do from the command line using `curl` (which you might have to install):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  306k  100  306k    0     0   113k      0  0:00:02  0:00:02 --:--:--  114k\n"
     ]
    }
   ],
   "source": [
    "! curl https://www.eisenhower.archives.gov/education/articles/Dr_Maxwell_Glen_Berry.pdf > /tmp/t.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That command downloads the file and because of the redirection operator, `>`, the output gets written to `t.pdf` up in `/tmp` directory.\n",
    "\n",
    "Once we have the data, we can pass the filename to `pdf2txt.py` to extract the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World War II Remembered is a multi-year exhibition currently on display at the Eisenhower Presidential Museum.  The \r\n",
      "article  that  follows  is  a  special  feature  of  this  exhibition,  the  sixth  in  a  series  created  to  honor  and  educate  about  the \r\n",
      "generation  that  won  World  War  II.    Featured  are  the  stories  of  real  people  from  the  “World  War  II  Participants  and \r\n",
      "Contemporaries” collection, held and preserved in the archives of the Eisenhower Presidential Library.   \r\n",
      " \r\n",
      "\r\n",
      "     Dr. Maxwell Glen Berry  \r\n",
      "     Mission, Kansas \r\n",
      "     U.S. Army, Pacific Theater \r\n",
      " \r\n"
     ]
    }
   ],
   "source": [
    "! pdf2txt.py /tmp/t.pdf | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, redirect that text to a file using the bash `>` operator or the `-o` option on `pdf2txt.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World War II Remembered is a multi-year exhibition currently on display at the Eisenhower Presidential Museum.  The \r\n",
      "article  that  follows  is  a  special  feature  of  this  exhibition,  the  sixth  in  a  series  created  to  honor  and  educate  about  the \r\n",
      "generation  that  won  World  War  II.    Featured  are  the  stories  of  real  people  from  the  “World  War  II  Participants  and \r\n",
      "Contemporaries” collection, held and preserved in the archives of the Eisenhower Presidential Library.   \r\n",
      " \r\n",
      "\r\n",
      "     Dr. Maxwell Glen Berry  \r\n",
      "     Mission, Kansas \r\n",
      "     U.S. Army, Pacific Theater \r\n",
      " \r\n"
     ]
    }
   ],
   "source": [
    "! pdf2txt.py /tmp/t.pdf > /tmp/t.txt\n",
    "! pdf2txt.py -o /tmp/t.txt /tmp/t.pdf\n",
    "! head -10 /tmp/t.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have text output, you can perform whatever analysis you'd like without having to worry about the data coming in PDF form. For example, you might want to run some analysis on financial documents but they are all in PDF. First, convert to text and then perform your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Read that text file and split the document into a list of words. Print out the first 100 words. It should look like:\n",
    "\n",
    "```\n",
    "['World', 'War', 'II', 'Remembered', 'is', 'a', 'multi-year', 'exhibition', ... ]\n",
    "```\n",
    "\n",
    "Import the `Counter` object which makes histograms from a list of elements:\n",
    "\n",
    "```python\n",
    "from collections import Counter\n",
    "```\n",
    "\n",
    "Then, if `words` is your list of words, create and print a histogram:\n",
    "\n",
    "```python\n",
    "print Counter(words)\n",
    "```\n",
    "\n",
    "The output starts like this:\n",
    "\n",
    "```\n",
    "Counter({'': 600, 'the': 52, 'of': 37, 'a': 31, 'and': 28, 'to': 26, '\\n': 26, 'in': 25, 'his': 19, 'he': 17, 'was': 16, 'Max': 14, 'that': 11, 'were': 9, '.': 9, 'had': 9, 'for': 9, 'with': 9, 'at': 9, '\\nand': 8, 'our': 8, 'I': 7, 'War': 6, 'on': 6, 'have': 5, 'as': 5, '\\nin': 5, '1945,': 4, 'would': 4, 'two': 4, 'Maxwell': 4, 'World': 4, 'University': 4, 'Josephine': 4, ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "A useful way to visualize histograms or word frequency is with a *word cloud*.  Augment your previous code to include packages for word clouds and graphics:\n",
    "\n",
    "```python\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "Next, take your histogram and get the top 50 words using function `histo.most_common(...)`. This returns a list of (word,count) tuples but we need it as a dictionary (`dict`) so convert using: `top = dict(...)`.\n",
    "\n",
    "To get the actual word cloud to appear, add this code to the end of your program:\n",
    "\n",
    "```python\n",
    "wordcloud = WordCloud(width=1800,\n",
    "                      height=1400,\n",
    "                      max_words=500,\n",
    "                      random_state=1,\n",
    "                      relative_scaling=0.25)\n",
    "wordcloud.fit_words(top)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "*Warning*: do not call your python file `wordcloud.py` as that is the package we are importing!\n",
    "\n",
    "When you run (passing a text file argument), you see something like:\n",
    "\n",
    "<img src=\"figures/wordcloud.png\" style=\"width:400px\">\n",
    "\n",
    "If you get stuck, see [cloud.py](https://github.com/parrt/msan692/blob/master/notes/code/cloud.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
